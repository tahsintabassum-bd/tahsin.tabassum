<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Journals</title>
    <link rel="stylesheet" href="assets/styles.css">
</head>
<body>
    <header>
        <nav>
            <ul class="navbar">
                <li><a href="index.html">Tahsin Tabassum</a></li>
                <li><a href="research.html">Research</a></li>
                <li class="dropdown">
                    <a class="dropbtn active">Publication</a>
                    <div class="dropdown-content">
                        <a href="journals.html">Journals</a>
                        <a href="conferences.html">Conferences</a>
                    </div>
                </li>
                <li><a href="contact.html">Contact</a></li>
                <li><a href="cv.html">CV</a></li>
            </ul>
        </nav>
    </header>

    <main>
        <h1>Journals</h1>
        <div class="journal-list">
            <div class="journal">
                <div class="journal-header">
                    <span class="tag">2024</span>
                    <h2><a href="https://iopscience.iop.org/article/10.1088/2057-1976/ad31f9/meta" target="_blank">Emotion recognition with reduced channels using CWT based EEG feature representation and a CNN classifier</a></h2>
                </div>
                <p class="authors">Md Sultan Mahmud, Shaikh Anowarul Fattah, Mohammad Saquib and Oishy Saha</p>
                <p class="year">In Biomedical Physics & Engineering Express, 10(4), p.045003.</p>
                <button class="abstract-toggle">View Abstract</button>
                <div class="abstract-content">
                    <p>
                        Objective. Although emotion recognition has been studied for decades, a more accurate classification method that requires less computing is still needed. At present, in many studies, EEG features are extracted from all channels to recognize emotional states, however, there is a lack of an efficient feature domain that improves classification performance and reduces the number of EEG channels. Approach. In this study, a continuous wavelet transform (CWT)-based feature representation of multi-channel EEG data is proposed for automatic emotion recognition. In the proposed feature, the time-frequency domain information is preserved by using CWT coefficients. For a particular EEG channel, each CWT coefficient is mapped into a strength-to-entropy component ratio to obtain a 2D representation. Finally, a 2D feature matrix, namely CEF2D, is created by concatenating these representations from different channels and fed into a deep convolutional neural network architecture. Based on the CWT domain energy-to-entropy ratio, effective channel and CWT scale selection schemes are also proposed to reduce computational complexity. Main results. Compared with previous studies, the results of this study show that valence and arousal classification accuracy has improved in both 3-class and 2-class cases. For the 2-class problem, the average accuracies obtained for valence and arousal dimensions are 98.83% and 98.95%, respectively, and for the 3-class, the accuracies are 98.25% and 98.68%, respectively. Significance. Our findings show that the entropy-based feature of EEG data in the CWT domain is effective for emotion recognition. Utilizing the proposed feature domain, an effective channel selection method can reduce computational complexity.
                    </p>
                </div>
            </div>

            <div class="journal">
                <div class="journal-header">
                    <span class="tag">2022</span>
                    <h2><a href="https://ieeexplore.ieee.org/document/9963974" target="_blank">Automatic Emotion Recognition from EEG Signal Utilizing Wavelet Packet Node Reconstruction and a CNN Classifier</a></h2>
                </div>
                <p class="authors">Oishy Saha, Md Sultan Mahmud, Shaikh Anowarul Fattah and Mohammad Saquib</p>
                <p class="year">In IEEE Access, 11, pp.2342-2350.</p>
                <button class="abstract-toggle">View Abstract</button>
                <div class="abstract-content">
                    <p>
                        Automatic emotion recognition using electroencephalogram (EEG) has obtained a wide range of attention in the domain of human-computer interaction (HCI) owing to the notable differences in brain activities in the event of different types of emotions. In this paper, a novel emotion recognition approach is proposed based on a deep learning scheme utilizing the temporal, spatial, and frequency effects of the EEG signal. As neural firing provides a pathway to elicit emotions, temporal, spatial, and frequency sub-band analysis of EEG signals uncovers salient information to categorize different classes of emotions. In this regard, temporal data from each channel are divided into major spectral bands and 2D signal matrices are constructed by combining the temporal information of different frequency band signals. After concatenating all signal matrices obtained from the available channels, a 3D feature space is obtained, which can better characterize emotion variations and, thus, better classification performance is obtained. The feature space is applied to a 2D deep neural network where the band information is passed to the depth dimension of the neural network. In order to highlight the important channels, a channel attention mechanism is proposed with the neural network to distribute the weights among the channels according to the contribution. Hence, the modified feature space effectively captures distinctive information about specific channels in the context of emotion recognition. In this study, detailed and extensive experimentations are carried out on a publicly available DEAP dataset and a very satisfactory performance is obtained for the valence and the arousal domain in 2-class scenario for the subject-dependent case. The average accuracies obtained for valence and arousal domain in binary class problem are 97.06% and 96.93%, respectively.
                    </p>
                </div>
            </div>
        </div>
    </main>

    <script src="assets/scripts.js"></script>
    
</body>
</html>
